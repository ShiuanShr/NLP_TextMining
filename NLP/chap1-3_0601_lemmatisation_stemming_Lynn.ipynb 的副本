{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNypjTGtoC_5"
   },
   "source": [
    "# 詞形還原(lemmatization)與詞幹提取(stemming)\n",
    "- Author: Lynn\n",
    "- Created: 2020/10\n",
    "- Reference: \n",
    "    - http://www.nltk.org/api/nltk.stem.html#nltk.stem.wordnet.WordNetLemmatizer\n",
    "    - https://www.machinelearningplus.com/nlp/lemmatization-examples-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "詞形還原(lemmatization)\n",
    "利用txt辭典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3YPTFglp7R4"
   },
   "source": [
    "### 詞形還原"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mmgxYDKirnWt",
    "outputId": "442ba6bb-343d-4039-8dba-7ebb6c966a3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "#自行查詢何謂wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p82h4da_qAHh",
    "outputId": "c14deae0-358c-4abe-ee4d-2b7ab03db0fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk\n",
      "apple\n",
      "beautiful\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "print(wnl.lemmatize('walked',pos='v')) #動詞    #emmatize辭型還原\n",
    "\n",
    "#pos= 詞性 \n",
    "print(wnl.lemmatize('apples',pos='n')) #名詞\n",
    "print(wnl.lemmatize('beautiful',pos='a')) #形容詞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbacWDLmGQq4"
   },
   "source": [
    "### 詞幹提取 Stemming\n",
    "\n",
    "利用演算法，重視normalize後的result，即使造成單辭殘缺，但使所有同意斯的詞統一，並不會對竟造成影響\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o74hQs0gFsGz",
    "outputId": "df52cf4a-e71d-448f-895e-6cd2c2cc4a91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walk\n",
      "walk\n",
      "walk\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Porter Stemmer \n",
    "from nltk.stem.porter import PorterStemmer  \n",
    "ps = PorterStemmer()\n",
    "print(ps.stem(word))\n",
    "\n",
    "# Lancaster Stemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "ls = LancasterStemmer()\n",
    "print(ls.stem(word))\n",
    "\n",
    "# Snowball Stemmer\n",
    "from nltk.stem import SnowballStemmer  \n",
    "ss = SnowballStemmer(\"english\")\n",
    "print(ss.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIqofXBIs_r6"
   },
   "source": [
    "### 比較 lemma 和 stem 的差別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "IYM7gNS2G414",
    "outputId": "2a63e0ef-8975-4ffb-fb1c-5025f8c1a97a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a10dbc5a307e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mlemma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mwnl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mstemming1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mstemming2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-a10dbc5a307e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mlemma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mwnl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mstemming1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mstemming2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ps' is not defined"
     ]
    }
   ],
   "source": [
    "# 假設已分詞完畢(split)\n",
    "words = ['apples','feet','leaves','stripes','meetings']\n",
    "#words = ['bad','worse','worst']\n",
    "#words = ['is','are','were']\n",
    "#words = ['walked', 'walks','walking'] + ['drinking','drank','drunk']\n",
    "#words = ['care','cared','caring']\n",
    "#words = ['good','better','best']\n",
    "\n",
    "lemma = [wnl.lemmatize(word,pos='n') for word in words]\n",
    "stemming1 = [ps.stem(word) for word in words]\n",
    "stemming2 = [ls.stem(word) for word in words]\n",
    "\n",
    "df = pd.DataFrame(list(zip(words,lemma,stemming1,stemming2)),\n",
    "                  columns=['words','WordNetLemmatizer','PorterStemmer','LancasterStemmer'])\n",
    "\n",
    "#zip 可取用多個串列 合併放在新的一個list中\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__3baCPithEE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lemmatisation&stemming.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
