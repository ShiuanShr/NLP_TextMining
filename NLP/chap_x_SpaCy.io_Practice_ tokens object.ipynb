{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chap_x_SpaCy.io_Practice_ tokens object.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMum4n13o2eUbh1I7e00U0l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Juqecj9sfn6M"},"source":["#!pip install spacy\n","#!python -m spacy download en\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wOom5_aicWW3"},"source":["from spacy.lang.en import English\n","\n","nlp = English() #利用spacy達成tokenize，先利用內建module，建立object\n","\n","#此函式具有processing pipeline 且有特定語言的規則，"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THvR406scrrM","executionInfo":{"status":"ok","timestamp":1622684338013,"user_tz":-480,"elapsed":671,"user":{"displayName":"yushiuan shr","photoUrl":"","userId":"06057505530621689871"}},"outputId":"2154ab0f-2b34-4228-8cbc-051dac38cc08"},"source":["# The doc object\n","\n","txt = 'I am a little piggy, I fall asleep during class.'\n","doc = nlp(txt)\n","\n","print(f'doc:{doc}')\n","#doc:I am a little piggy, I fall asleep during class.\n","\n","print(f'doc type:{type(doc)}')\n","#doc type:<class 'spacy.tokens.doc.Doc'>\n","\n","for tokens in doc:\n","  #print(tokens) vs    print(tokens.text) 差別在哪??? type(tokens)無法印出，why?\n","  #  這是token類別   /  這是STRING\n","  print(tokens.text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["doc:I am a little piggy, I fall asleep during class.\n","doc type:<class 'spacy.tokens.doc.Doc'>\n","I\n","am\n","a\n","little\n","piggy\n",",\n","I\n","fall\n","asleep\n","during\n","class\n",".\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DOXIMTwPhZZO"},"source":["# The tokens object\n","\n","\n","token可換成其他變數名稱，只要他是在迴圈list中的element的概念，即可使用後面之參數( lexical attribute)\n","```\n","doc = nlp('It costs $5.') #功能為印出index\n","print(token.i for token in doc)\n","#[0,1,2,3,4]\n","\n","token.text   #功能為印出內容\n","#['It', 'costs', '$', '5','.']  #結果不包含空格\n","\n","token.is_alpha\n","#[True, True, False, False, False]\n","\n","token.is_punct\n","#[False, False, False, False, True]\n","\n","token.like_num  #注意 是like 不是is\n","#[False, False, False, True, False]\n","```\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ypFHx6wbeUcF","executionInfo":{"status":"ok","timestamp":1622686570353,"user_tz":-480,"elapsed":417,"user":{"displayName":"yushiuan shr","photoUrl":"","userId":"06057505530621689871"}},"outputId":"6418f533-3929-4c2b-b995-c1650075c48f"},"source":["# Import the Spanish language class\n","from spacy.lang.es import Spanish\n","\n","# Create the nlp object\n","nlp = Spanish()\n","\n","# Process a text (this is Spanish for: \"How are you?\")\n","doc = nlp(\"¿Cómo estás?\")\n","\n","# Print the document text\n","print(doc.text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["¿Cómo estás?\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jCQV6xOjqFMX","executionInfo":{"status":"ok","timestamp":1622686949543,"user_tz":-480,"elapsed":419,"user":{"displayName":"yushiuan shr","photoUrl":"","userId":"06057505530621689871"}},"outputId":"4b6d20e2-64e3-4561-8634-2dece5d619af"},"source":["# Import the English language class and create the nlp object\n","from spacy.lang.en import English\n","\n","nlp = English()\n","\n","# Process the text\n","doc = nlp(\"I like tree kangaroos and narwhals.\")\n","\n","# Select the first token\n","first_token = doc[0]\n","print(f'type(first_token): {type(first_token)}') #result type = token\n","# Print the first token's text\n","print(first_token.text) #result type = string\n","print(f'type(first_token.text): {type(first_token.text)}')\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["type(first_token): <class 'spacy.tokens.token.Token'>\n","I\n","type(first_token.text): <class 'str'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GGZaAOFXtpbR"},"source":["# 練習運用 lexical attribute 取得百分比(%)\n","\n","use spaCy’s Doc and Token objects, and lexical attributes to find percentages in a text. You’ll be looking for two subsequent tokens: a number and a percent sign.\n","\n","Use the like_num token attribute to check whether a token in the doc resembles a number.\n","Get the token following the current token in the document. The index of the next token in the doc is token.i + 1.\n","Check whether the next token’s text attribute is a percent sign ”%“.\n"]},{"cell_type":"code","metadata":{"id":"e0oCmhycq101"},"source":["from spacy.lang.en import English\n","\n","nlp = English()\n","\n","# Process the text\n","doc = nlp(\n","    \"In 1990, more than 60% of people in East Asia were in extreme poverty. \"\n","    \"Now less than 4% are.\"\n",")\n","\n","# Iterate over the tokens in the doc\n","for token in doc:\n","    # Check if the token resembles a number\n","    if token.like_num:\n","        # Get the next token in the document\n","        next_token = doc[token.i+1]\n","        # Check if the next token's text equals \"%\"\n","        if next_token.text == \"%\":\n","            print(\"Percentage found:\", token.text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0HJEnf2MZQkM"},"source":["# 2. Spacy 流水线 和 属性\n","  -2.1 Tokenization\n","\n","  -2.2 Part of Speech Tagging (词性标注)\n","\n","  -2.3 Entity Detection （实体检测）\n","\n","  -2.4 Dependency Parsing\n","\n","  -2.5 Noun Phrases （名词短语）\n","\n","  -3 CNTK和core NLP 的对比\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"99uHc0HKZuQ2"},"source":["# 2.1 Tokenization"]},{"cell_type":"code","metadata":{"id":"bQUe6caRZg5E"},"source":["#安裝\n","import spacy \n","nlp = spacy.load(“en”)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ifhog4UjaRiK","executionInfo":{"status":"ok","timestamp":1622716502806,"user_tz":-480,"elapsed":302,"user":{"displayName":"yushiuan shr","photoUrl":"","userId":"06057505530621689871"}},"outputId":"8e8e17a1-2d7d-490c-dfab-c8ddabda357a"},"source":["#導入文本\n","from google.colab import drive\n","import pandas as pd\n","drive.mount('/content/gdrive') # 此處需要登入google帳號\n","# 獲取授權碼之後輸入即可連動雲端硬碟\n","data = pd.read_csv(\"/content/gdrive/MyDrive/AI_&_EdgeComputing_Program/NLP/shared_folder/dataset/bbcnews.txt\",error_bad_lines=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["b'Skipping line 3: expected 1 fields, saw 2\\nSkipping line 9: expected 1 fields, saw 3\\nSkipping line 11: expected 1 fields, saw 2\\nSkipping line 12: expected 1 fields, saw 2\\nSkipping line 15: expected 1 fields, saw 3\\n'\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"my79LvQxcdQO"},"source":["1.使用pandas.read_csv(filePath)方法來讀取csv文件時，可能會出現這種錯誤：\n","ParserError：Error tokenizing data.C error:Expected 2 fields in line 407,saw 3.\n","這句話的意思是，在csv文件的第407行數據，期待2個字段，但在第407行實際發現了3個字段。\n","原因：header只有兩個字段名，但數據的第407行卻出現了3個字段（可能是該行數據包含了逗號，或者確實有三個部分），導致pandas不知道該如何處理。\n","解決辦法:把第407行多出的字段刪除，或者通過在read_csv方法中設置error_bad_lines=False來忽略這種錯誤：\n","改為"]},{"cell_type":"markdown","metadata":{"id":"VqGhkwp12Szc"},"source":["#Spacy doc 資料型態常用attribute\n","- doc.ents : 當資料為doc data structure，會挑選專有名詞，回傳由專有名詞組成的turple，我們可再利用list()將轉為List輸出 \n","\n","\n","https://spacy.io/api/doc#ents\n"]},{"cell_type":"code","metadata":{"id":"2fkt1Au6Y1bQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622724230376,"user_tz":-480,"elapsed":926,"user":{"displayName":"yushiuan shr","photoUrl":"","userId":"06057505530621689871"}},"outputId":"29dd16b4-eeaa-4d52-d8e9-a03c03382df3"},"source":["doc = nlp(\"Mr. Best flew to New York on Saturday morning.\")\n","\n","ents = list(doc.ents)\n","\n","###################################################\n","print('type(doc.ents): ',type(doc.ents))\n","#type(doc.ents):  <class 'tuple'>\n","print('doc.ents: ',doc.ents)\n","#doc.ents:  (Best, New York, Saturday, morning)\n","###################################################\n","\n","#ents: [Best, New York, Saturday, morning]\n","print('ents[0].label_: ',ents[0].label_) # PERSON 回傳詞性\n","print('ents[0].text: ',ents[0].text)   # Best  回傳內文\n","\n","\n","###################################################\n","\n","print(ents[0].label_ == \"PERSON\")   \n","print(ents[0].text == \"Mr. Best\")  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["type(doc.ents):  <class 'tuple'>\n","doc.ents:  (Best, New York, Saturday, morning)\n","ents[0].label_:  PERSON\n","ents[0].text:  Best\n","True\n","False\n"],"name":"stdout"}]}]}